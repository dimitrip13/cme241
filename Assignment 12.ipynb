{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change notebook width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import *\n",
    "from rl.markov_decision_process import *\n",
    "from rl.markov_process import *\n",
    "from rl.distribution import *\n",
    "from rl.dynamic_programming import *\n",
    "from rl.returns import *\n",
    "from scipy.stats import poisson\n",
    "import pprint as pp\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "from rl.monte_carlo import mc_prediction\n",
    "from rl.td import td_prediction\n",
    "from rl.function_approx import Tabular\n",
    "from rl.function_approx import FunctionApprox\n",
    "from rl.markov_process import FiniteMarkovRewardProcess\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = TypeVar('S')\n",
    "A = TypeVar('A')\n",
    "V = Mapping[S, float]\n",
    "\n",
    "# Return a Value Function mapping of zeros and a mapping of state counts that's also zeros \n",
    "# This function is used in both Problem 1 + 2\n",
    "def initiate_VF_plus_Counts(states):\n",
    "    # Start with empty value function\n",
    "    vf: Mapping[S, float] = {}\n",
    "        \n",
    "    # Create a dictionary to keep count of the number of times a state has been visited\n",
    "    state_counts: Mapping[S, int] = {}\n",
    "        \n",
    "    # Loop over each state and add the zeros \n",
    "    for state in states:\n",
    "        vf[state] = 0.0\n",
    "        state_counts[state] = 0\n",
    "        \n",
    "    return vf, state_counts\n",
    "\n",
    "def calculate_Gt_n(transitions, vf, γ, idx, n, approx=False):\n",
    "    last_idx = min(idx + n, len(transitions) - 1)\n",
    "    G = 0\n",
    "    for k, T in enumerate(itertools.islice(transitions, idx, last_idx)):\n",
    "        G += γ**k * T.reward\n",
    "        bootstrapped_state = T.state # Only need last state\n",
    "    if approx:\n",
    "        G += γ**(last_index - idx) * vf(bootstrapped_state)\n",
    "    else: # Tabular / not usung an approximate vf\n",
    "        G += γ**(last_index - idx) * vf[bootstrapped_state]\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# n step bootstrap algorithm for the tabular case where all states are defined and discrete\n",
    "def n_step_tabular_bootstrap(\n",
    "    transitions: Iterable[TransitionStep[S]],\n",
    "    vf: V,\n",
    "    state_counts: Mapping[S, int],    # Dictionary of counts per state\n",
    "    γ: float = .9,                    # Discount Factor\n",
    "    n: int = 3,                       # Number to steps to look ahead\n",
    "    αi: float = .1,                   # Initial learning rate\n",
    "    num_transitions: float = 1000,    # Number of transitions to loop through\n",
    "    half_life: float = 1000.,\n",
    "    exponent: float = 0.5,\n",
    "    tolerance: float = 1e-6\n",
    "                                                                ) -> V: # Value function\n",
    "    \n",
    "    for i, transition in enumerate(transitions):\n",
    "        # Break if number of transitions reached\n",
    "        if i == num_transitons:\n",
    "            break\n",
    "        \n",
    "        # Get current state from tansition\n",
    "        cur_state = transiton.state\n",
    "        \n",
    "        # Increment State counts and checks if in dictionary\n",
    "        if cur_state in state_counts: \n",
    "            state_counts[cur_state] += 1\n",
    "        else: \n",
    "            state_counts[cur_state] = 1\n",
    "        \n",
    "        # Update learning rate\n",
    "        α = αi / (1 + ((state_counts[cur_state] - 1) / half_life)**exponent)\n",
    "        \n",
    "        # Get G_{t,n} the n-step bootstrapped return \n",
    "        G = calculate_Gt_n(transitions, vf, γ, i, n, False)\n",
    "            \n",
    "        # Update Value funtion Approximation\n",
    "        vf.update([ cur_state, vf[cur_state] * α * (Gt_n - vf[cur_state]) ])\n",
    "        \n",
    "    return vf\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# n step bootstrap algorithm for the function approximation case where the value function is approximated\n",
    "def n_step_funcapprox_bootstrap(\n",
    "    transitions: Iterable[TransitionStep[S]], \n",
    "    state_counts: Mapping[S, int],\n",
    "    vf: FunctionApprox[S],\n",
    "    γ: float,\n",
    "    n: int,\n",
    "    αi: float,\n",
    "    num_transitions: int = 1000\n",
    "                                                            ) -> FunctionApprox[S]:\n",
    "    \n",
    "    for i, transition in enumerate(transitions):\n",
    "        # Break if number of transitions reached\n",
    "        if i == num_transitons:\n",
    "            break\n",
    "        \n",
    "        # Get current state from tansition\n",
    "        cur_state = transiton.state\n",
    "        \n",
    "        # Increment State counts and checks if in dictionary\n",
    "        if cur_state in state_counts: \n",
    "            state_counts[cur_state] += 1\n",
    "        else: \n",
    "            state_counts[cur_state] = 1\n",
    "        \n",
    "        # Update learning rate\n",
    "        α = αi / (1 + ((state_counts[cur_state] - 1) / half_life)**exponent)\n",
    "        \n",
    "        # Get G_{t,n} the n-step bootstrapped return \n",
    "        G = calculate_Gt_n(transitions, vf, γ, i, n, True)\n",
    "            \n",
    "        # Update Value funtion Approximation\n",
    "        vf.update([ cur_state, vf(cur_state) * α * (Gt_n - vf(cur_state)) ])\n",
    "        \n",
    "    return vf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabular_td_lambda(\n",
    "    transitions: Iterable[TransitionStep[S]],\n",
    "    vf: V,\n",
    "    state_counts: Mapping[S, int],\n",
    "    γ: float,\n",
    "    α: float,\n",
    "    λ:float,\n",
    "    eligibility_trace: Dict[S, float],\n",
    "    num_transitions: float = 1000,\n",
    "    half_life: float = 1000.,\n",
    "    exponent: float = 0.5,\n",
    "        \n",
    "                                                        ) -> V: # Value function\n",
    "    \n",
    "    for i, step in enumerate(transitions):\n",
    "        # Break if number of transitions reached\n",
    "        if i == num_transitions:\n",
    "            break\n",
    "        \n",
    "        # Get State, Next State, and Reward values\n",
    "        cur_state = step.state\n",
    "        next_state = step.next_state\n",
    "        reward = step.reward\n",
    "        \n",
    "        # Update Dictionary of eligibility\n",
    "        eligibility_trace = {state: γ*λ*eligibility for state, eligibility in eligibility_traces.items()}\n",
    "        # Increment eligibility of current state and checks if state is in dictionary\n",
    "        if cur_state in eligibility_trace: \n",
    "            eligibility_trace[cur_state] += 1 \n",
    "        else: \n",
    "            eligibility_trace[cur_state] = 1 \n",
    "        \n",
    "        # Increment state counts\n",
    "        state_counts[cur_state] += 1   \n",
    "        \n",
    "        # Update value function\n",
    "        vf[state] += α * (reward + γ * vf[next_state] - vf[cur_state]) * eligibility_trace[state]\n",
    "    \n",
    "    return vf\n",
    "\n",
    "\n",
    "def approx_td_lambda(\n",
    "    transitions: Iterable[TransitionStep[S]],\n",
    "    state_counts: Mapping[S, int],\n",
    "    γ: float,\n",
    "    λ: float,\n",
    "    vf: FunctionApprox[S],\n",
    "    α: float = 0.01\n",
    "                                                                    ) -> FunctionApprox[S]:\n",
    "    \n",
    "    for i, step in enumerate(transitions):\n",
    "        # Break if number of transitions reached\n",
    "        if i == num_transitions:\n",
    "            break\n",
    "        \n",
    "        # Get State, Next State, and Reward values\n",
    "        cur_state = step.state\n",
    "        next_state = step.next_state\n",
    "        reward = step.reward\n",
    "        \n",
    "        # Update Dictionary of eligibility\n",
    "        eligibility_trace = {state: γ*λ*eligibility for state, eligibility in eligibility_traces.items()}\n",
    "        # Increment eligibility of current state and checks if state is in dictionary\n",
    "        if cur_state in eligibility_trace:\n",
    "            eligibility_trace[cur_state] += 1\n",
    "        else: \n",
    "            eligibility_trace[cur_state] = 1 \n",
    "        \n",
    "        # Update value function\n",
    "        vf.update([ cur_state, vf(cur_state) * α * (Gt_n - vf(cur_state)) ])\n",
    "    \n",
    "    return vf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
